{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator network for Conditional GAN. Takes in noise vector and class labels to generate images.\n",
    "    \"\"\"\n",
    "    def __init__(self, noise_dim, num_classes, img_channels, embedding_dim):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "\n",
    "        self.label_embed = nn.Embedding(num_classes, embedding_dim)  # Embed class labels\n",
    "\n",
    "        # Fully connected and transpose conv layers for upsampling\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim + embedding_dim, 1024*4*4),           # Output: (batch, 1024*4*4)\n",
    "            nn.BatchNorm1d(1024*4*4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (1024, 4, 4)),                             # Output: (batch, 1024, 4, 4)\n",
    "\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1),                    # Output: (batch, 512, 8, 8)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),                     # Output: (batch, 256, 16, 16)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),                     # Output: (batch, 128, 32, 32)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),                      # Output: (batch, 64, 64, 64)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1),            # Output: (batch, 3, 128, 128)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, class_labels, noise):\n",
    "        label_embed = self.label_embed(class_labels)                  # Output: (batch, embedding_dim)\n",
    "        x = torch.cat((noise, label_embed), dim=1)                   # Concatenate noise + labels\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator for Conditional GAN. Takes images and labels to output probability of realness.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, img_channels, embedding_dim):\n",
    "        super(ConditionalDiscriminator, self).__init__()\n",
    "\n",
    "        self.label_embed = nn.Embedding(num_classes, embedding_dim)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(embedding_dim + img_channels, 64, 4, 2, 1),     # Output: (batch, 64, 128, 128)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),                              # Output: (batch, 128, 64, 64)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),                             # Output: (batch, 256, 32, 32)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),                             # Output: (batch, 512, 16, 16)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1),                            # Output: (batch, 1024, 8, 8)\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(1024, 1, 4, 1, 0),                              # Output: (batch, 1, 5, 5)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, class_labels, image):\n",
    "        label_embed = self.label_embed(class_labels).unsqueeze(2).unsqueeze(3)  # Output: (batch, embedding_dim, 1, 1)\n",
    "        label_embed = label_embed.expand(-1, -1, image.size(2), image.size(3)) # Expand to (batch, embedding_dim, H, W)\n",
    "        x = torch.cat((image, label_embed), dim=1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(Generator, Discriminator, G_optimizer, D_optimizer, criterion, device, train_dataloader, num_classes, noise_dim, num_epoch):\n",
    "    \"\"\"\n",
    "    Trains the Conditional GAN model.\n",
    "    \"\"\"\n",
    "    D_losses, G_losses = [], []\n",
    "\n",
    "    print(\"Training started...\\n\")\n",
    "    for epoch in range(num_epoch):\n",
    "        total_D_loss, total_G_loss = 0, 0\n",
    "\n",
    "        for i, (real_images, labels) in enumerate(train_dataloader):\n",
    "            real_images = real_images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            batch_size = real_images.size(0)\n",
    "\n",
    "            # Train Discriminator\n",
    "            noise = torch.randn((batch_size, noise_dim)).to(device)\n",
    "            fake_labels = torch.randint(0, num_classes, (batch_size,), device=device)\n",
    "            fake_images = Generator(fake_labels, noise)\n",
    "\n",
    "            D_real = Discriminator(labels, real_images)\n",
    "            D_fake = Discriminator(fake_labels.detach(), fake_images.detach())\n",
    "\n",
    "            real_loss = criterion(D_real, torch.ones_like(D_real))\n",
    "            fake_loss = criterion(D_fake, torch.zeros_like(D_fake))\n",
    "            D_loss = real_loss + fake_loss\n",
    "\n",
    "            D_optimizer.zero_grad()\n",
    "            D_loss.backward()\n",
    "            D_optimizer.step()\n",
    "            total_D_loss += D_loss.item()\n",
    "\n",
    "            # Train Generator\n",
    "            noise = torch.randn((batch_size, noise_dim)).to(device)\n",
    "            fake_labels = torch.randint(0, num_classes, (batch_size,), device=device)\n",
    "            fake_images = Generator(fake_labels, noise)\n",
    "\n",
    "            D_fake = Discriminator(fake_labels, fake_images)\n",
    "            G_loss = criterion(D_fake, torch.ones_like(D_fake))\n",
    "\n",
    "            G_optimizer.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()\n",
    "            total_G_loss += G_loss.item()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Batch {i}/{len(train_dataloader)}: D_loss = {D_loss.item():.4f}, G_loss = {G_loss.item():.4f}\")\n",
    "\n",
    "        avg_D_loss = total_D_loss / len(train_dataloader)\n",
    "        avg_G_loss = total_G_loss / len(train_dataloader)\n",
    "        D_losses.append(avg_D_loss)\n",
    "        G_losses.append(avg_G_loss)\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}/{num_epoch}] âž¤ D_loss: {avg_D_loss:.4f}, G_loss: {avg_G_loss:.4f}\")\n",
    "\n",
    "    return Generator, D_losses, G_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(Generator, noise_dim, device):\n",
    "    \"\"\"\n",
    "    Generates and visualizes samples using the trained generator.\n",
    "    \"\"\"\n",
    "    print(\"Generating images with trained Generator...\\n\")\n",
    "    Generator.eval()\n",
    "\n",
    "    noise = torch.randn((101, noise_dim)).to(device)\n",
    "    labels = torch.arange(0, 101).to(device)\n",
    "    generated_images = Generator(labels, noise)\n",
    "\n",
    "    vutils.save_image(generated_images, \"cgan_samples.png\", nrow=5, normalize=True)\n",
    "    generated_images = generated_images * 0.5 + 0.5\n",
    "\n",
    "    grid = vutils.make_grid(generated_images.detach().cpu(), nrow=5, padding=2, normalize=False)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Generated Images\")\n",
    "    plt.imshow(grid.permute(1, 2, 0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    noise_dim = 256\n",
    "    num_classes = 101\n",
    "    embedding_dim = 100\n",
    "    batch_size = 64\n",
    "    G_lr = 2e-4\n",
    "    D_lr = 1e-4\n",
    "    num_epoch = 100\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
    "    ])\n",
    "    \n",
    "    print(\"Loading dataset...\\n\")\n",
    "    train_data = torchvision.datasets.Food101(root=\"./data\", split=\"train\", download=True, transform=transform)\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    Generator = ConditionalGenerator(noise_dim, num_classes, img_channels=3, embedding_dim=embedding_dim).to(device)\n",
    "    Discriminator = ConditionalDiscriminator(num_classes, img_channels=3, embedding_dim=embedding_dim).to(device)\n",
    "\n",
    "    G_optimizer = torch.optim.Adam(Generator.parameters(), lr=G_lr, betas=(0.5, 0.999))\n",
    "    D_optimizer = torch.optim.Adam(Discriminator.parameters(), lr=D_lr, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    trained_generator, D_losses, G_losses = train_model(\n",
    "        Generator,\n",
    "        Discriminator,\n",
    "        G_optimizer,\n",
    "        D_optimizer,\n",
    "        criterion,\n",
    "        device,\n",
    "        train_dataloader,\n",
    "        num_classes,\n",
    "        noise_dim,\n",
    "        num_epoch\n",
    "    )\n",
    "\n",
    "    # Plot training losses\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "\n",
    "    axes[0].plot(range(1, num_epoch + 1), D_losses, label=\"Discriminator_losses\", color='blue')\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(\"Discriminator Loss vs Epoch\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(range(1, num_epoch + 1), G_losses, label=\"Generator_losses\", color='red')\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Loss\")\n",
    "    axes[1].set_title(\"Generator Loss vs Epoch\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    evaluate_model(trained_generator, noise_dim, device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
